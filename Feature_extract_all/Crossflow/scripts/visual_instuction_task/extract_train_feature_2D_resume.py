"""
This file is used to extract feature of the demo training data.
Multi-GPU parallel version using Accelerate.
"""

import os
import shutil
import sys
# å¾€ä¸Šä¸¤çº§åˆ° Crossflow ç›®å½•ï¼Œä»¥ä¾¿è®¿é—® libs æ¨¡å—
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

import torch
import numpy as np
from tqdm import tqdm
from PIL import Image
import einops
import time
import re
import libs.autoencoder
from transformers import AutoModelForCausalLM
from torch.utils.data import Dataset, DataLoader
from accelerate import Accelerator
from accelerate.utils import gather_object

print("sys.path:",sys.path)
original_sys_path = sys.path.copy()
crossflow_parent_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
janus_dir = os.path.join(crossflow_parent_dir, "Janus")
# sys.path.insert(0, os.path.abspath(janus_dir))
from janus.models import MultiModalityCausalLM, VLChatProcessor
from janus.utils.io import load_pil_images
sys.path = original_sys_path  # ç›´æ¥æ¢å¤

def recreate_folder(folder_path):
    if os.path.exists(folder_path):
        shutil.rmtree(folder_path)
    os.makedirs(folder_path)

def extract_number_key(filename):
    """
    ä»æ–‡ä»¶åä¸­æå–åŒ¹é…é”®ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    
    ç¤ºä¾‹ï¼š
    - '000001_00000303_textbox.png' -> '000001_00000303'
    - '000001_00000303_edit.png' -> '000001_00000303'
    - '996de8d0-1585-4612-ba08-3f3dadf147bd_render.JPEG' -> '996de8d0-1585-4612-ba08-3f3dadf147bd'
    - '996de8d0-1585-4612-ba08-3f3dadf147bd.jpg' -> '996de8d0-1585-4612-ba08-3f3dadf147bd'
    - 'image_000003.JPEG' -> 'image_000003'
    
    æ”¯æŒæ ¼å¼ï¼š
    - UUIDæ ¼å¼ï¼š'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx'
    - æ•°å­—å’Œä¸‹åˆ’çº¿ç»„åˆï¼š'000001_00000303'
    - æ–‡ä»¶åä¸»ä½“ï¼ˆå»é™¤å¸¸è§åç¼€ï¼‰ï¼š'image_000003'
    """
    basename = os.path.splitext(filename)[0]  # ç§»é™¤æ‰©å±•å
    
    # ç­–ç•¥1: å°è¯•æå–UUIDæ ¼å¼ï¼ˆ8-4-4-4-12ï¼‰
    # ä¾‹å¦‚ï¼š996de8d0-1585-4612-ba08-3f3dadf147bd
    uuid_pattern = r'([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})'
    uuid_match = re.search(uuid_pattern, basename, re.IGNORECASE)
    if uuid_match:
        return uuid_match.group(1).lower()  # ç»Ÿä¸€è½¬å°å†™
    
    # ç­–ç•¥2: å»é™¤å¸¸è§çš„åç¼€ï¼ˆ_render, _edit, _output, _input, _src, _dstç­‰ï¼‰
    # è¿™æ · 'abc_render' å’Œ 'abc' ä¼šåŒ¹é…åˆ°ç›¸åŒçš„é”® 'abc'
    common_suffixes = [
        '_render', '_edit', '_output', '_input', 
        '_src', '_dst', '_source', '_target',
        '_textbox', '_mask', '_original', '_processed'
    ]
    cleaned_basename = basename
    for suffix in common_suffixes:
        if cleaned_basename.endswith(suffix):
            cleaned_basename = cleaned_basename[:-len(suffix)]
            break
    
    # ç­–ç•¥3: å°è¯•åŒ¹é…å¼€å¤´çš„è¿ç»­æ•°å­—å’Œä¸‹åˆ’çº¿æ¨¡å¼
    # ä¾‹å¦‚ï¼š000001_00000303
    match = re.search(r'^(\d+(?:_\d+)*)', cleaned_basename)
    if match:
        return match.group(1)
    
    # ç­–ç•¥4: å¦‚æœä¸Šé¢éƒ½ä¸åŒ¹é…ï¼Œè¿”å›æ¸…ç†åçš„basename
    # è¿™æ · 'image_000003_render' å’Œ 'image_000003' éƒ½ä¼šè¿”å› 'image_000003'
    if cleaned_basename != basename:
        return cleaned_basename
    
    # ç­–ç•¥5: å°è¯•æå–æ‰€æœ‰æ•°å­—éƒ¨åˆ†å¹¶ç”¨ä¸‹åˆ’çº¿è¿æ¥
    numbers = re.findall(r'\d+', basename)
    if numbers:
        return '_'.join(numbers)
    
    # å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›åŸå§‹basename
    return basename

def center_crop_arr(pil_image, image_size):
    while min(*pil_image.size) >= 2 * image_size:
        pil_image = pil_image.resize(
            tuple(x // 2 for x in pil_image.size), resample=Image.BOX
        )

    scale = image_size / min(*pil_image.size)
    pil_image = pil_image.resize(
        tuple(round(x * scale) for x in pil_image.size), resample=Image.BICUBIC
    )

    arr = np.array(pil_image)
    crop_y = (arr.shape[0] - image_size) // 2
    crop_x = (arr.shape[1] - image_size) // 2
    return arr[crop_y : crop_y + image_size, crop_x : crop_x + image_size]


class ImageFeatureDataset(Dataset):
    """è‡ªå®šä¹‰æ•°æ®é›†ç±»ï¼Œç”¨äºå¹¶è¡ŒåŠ è½½å’Œå¤„ç†å›¾åƒ
    
    æ”¯æŒä»ä¸¤ä¸ªä¸åŒçš„è·¯å¾„åŠ è½½å›¾åƒï¼š
    - input_image_path: ç”¨äºæå–embeddingså’Œmasksï¼ˆè¾“å…¥å›¾åƒï¼‰
    - output_image_path: ç”¨äºæå–momentsï¼ˆè¾“å‡ºå›¾åƒï¼‰
    
    è¾“å…¥å’Œè¾“å‡ºå›¾åƒé€šè¿‡æ™ºèƒ½æ–‡ä»¶ååŒ¹é…è¿›è¡Œé…å¯¹ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼š
    
    ç¤ºä¾‹1 - UUIDæ ¼å¼ï¼š
    - è¾“å…¥ï¼š{class_label}/996de8d0-1585-4612-ba08-3f3dadf147bd_render.JPEG
    - è¾“å‡ºï¼š{class_label}/996de8d0-1585-4612-ba08-3f3dadf147bd.jpg
    - åŒ¹é…é”®ï¼š996de8d0-1585-4612-ba08-3f3dadf147bd
    
    ç¤ºä¾‹2 - æ•°å­—IDæ ¼å¼ï¼š
    - è¾“å…¥ï¼š000001_00000303_textbox.png
    - è¾“å‡ºï¼š000001_00000303_edit.png
    - åŒ¹é…é”®ï¼š000001_00000303
    
    ç¤ºä¾‹3 - æ–‡ä»¶åæ ¼å¼ï¼š
    - è¾“å…¥ï¼šimage_000003.JPEG
    - è¾“å‡ºï¼šimage_000003.png
    - åŒ¹é…é”®ï¼šimage_000003
    """
    def __init__(self, input_image_path, output_image_path, save_dir=None, skip_processed=True, recursive=True):
        self.input_image_path = input_image_path
        self.output_image_path = output_image_path
        
        scan_mode = "é€’å½’æ‰«æï¼ˆåŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼‰" if recursive else "ä»…æ‰«æé¡¶å±‚ç›®å½•"
        print(f"[æ•°æ®é›†] å¼€å§‹{scan_mode}:")
        print(f"  - è¾“å…¥å›¾åƒè·¯å¾„ï¼ˆembeddings/masksï¼‰: {input_image_path}")
        print(f"  - è¾“å‡ºå›¾åƒè·¯å¾„ï¼ˆmomentsï¼‰: {output_image_path}")
        scan_start = time.time()
        
        valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
        
        # Step 1: æ‰«æè¾“å…¥å›¾åƒè·¯å¾„
        all_input_files = []
        if recursive:
            for root, dirs, files in os.walk(input_image_path):
                for filename in files:
                    ext = os.path.splitext(filename)[1].lower()
                    if ext in valid_extensions:
                        rel_path = os.path.relpath(os.path.join(root, filename), input_image_path)
                        all_input_files.append(rel_path)
        else:
            with os.scandir(input_image_path) as entries:
                for entry in entries:
                    if entry.is_file():
                        ext = os.path.splitext(entry.name)[1].lower()
                        if ext in valid_extensions:
                            all_input_files.append(entry.name)
        
        all_input_files.sort()
        print(f"[æ•°æ®é›†] è¾“å…¥è·¯å¾„æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(all_input_files)} å¼ å›¾ç‰‡")
        
        # ğŸ” è°ƒè¯•ï¼šæ‰“å°æ–‡ä»¶åˆ—è¡¨çš„å‰10ä¸ªå’Œå10ä¸ªï¼Œç”¨äºéªŒè¯æ’åºç¨³å®šæ€§
        if len(all_input_files) > 0:
            print(f"[æ•°æ®é›†] æ–‡ä»¶åˆ—è¡¨ç¤ºä¾‹ï¼ˆå‰5ä¸ªï¼‰: {all_input_files[:5]}")
            if len(all_input_files) > 5:
                print(f"[æ•°æ®é›†] æ–‡ä»¶åˆ—è¡¨ç¤ºä¾‹ï¼ˆå5ä¸ªï¼‰: {all_input_files[-5:]}")
        
        # Step 2: æ‰«æè¾“å‡ºå›¾åƒè·¯å¾„å¹¶å»ºç«‹æ•°å­—é”®æ˜ å°„
        output_map = {}  # æ•°å­—é”® -> è¾“å‡ºå›¾åƒç›¸å¯¹è·¯å¾„
        output_key_conflicts = {}  # è®°å½•é”®å†²çª
        total_output_files = 0
        
        if recursive:
            for root, dirs, files in os.walk(output_image_path):
                for filename in files:
                    ext = os.path.splitext(filename)[1].lower()
                    if ext in valid_extensions:
                        total_output_files += 1
                        rel_path = os.path.relpath(os.path.join(root, filename), output_image_path)
                        # æå–æ•°å­—é”®
                        number_key = extract_number_key(os.path.basename(filename))
                        
                        # ï¿½ï¿½ æ£€æµ‹é”®å†²çª
                        if number_key in output_map:
                            if number_key not in output_key_conflicts:
                                output_key_conflicts[number_key] = [output_map[number_key]]
                            output_key_conflicts[number_key].append(rel_path)
                        
                        output_map[number_key] = rel_path
        else:
            with os.scandir(output_image_path) as entries:
                for entry in entries:
                    if entry.is_file():
                        ext = os.path.splitext(entry.name)[1].lower()
                        if ext in valid_extensions:
                            total_output_files += 1
                            number_key = extract_number_key(entry.name)
                            
                            # ğŸ” æ£€æµ‹é”®å†²çª
                            if number_key in output_map:
                                if number_key not in output_key_conflicts:
                                    output_key_conflicts[number_key] = [output_map[number_key]]
                                output_key_conflicts[number_key].append(entry.name)
                            
                            output_map[number_key] = entry.name
        
        print(f"[æ•°æ®é›†] è¾“å‡ºè·¯å¾„æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {total_output_files} ä¸ªæ–‡ä»¶ï¼Œ{len(output_map)} ä¸ªå”¯ä¸€é”®")
        
        # ğŸ” è­¦å‘Šé”®å†²çª
        if output_key_conflicts:
            print(f"[æ•°æ®é›†] âš ï¸ è­¦å‘Šï¼šæ£€æµ‹åˆ° {len(output_key_conflicts)} ä¸ªé”®å†²çªï¼ˆå¤šä¸ªæ–‡ä»¶æ˜ å°„åˆ°åŒä¸€ä¸ªé”®ï¼‰ï¼")
            print(f"[æ•°æ®é›†]       è¿™ä¼šå¯¼è‡´é‡å¤å¤„ç†ï¼å†²çªç¤ºä¾‹ï¼ˆå‰3ä¸ªï¼‰:")
            for i, (key, paths) in enumerate(list(output_key_conflicts.items())[:3]):
                print(f"[æ•°æ®é›†]       é”® '{key}' å†²çªæ–‡ä»¶: {paths}")
        
        # Step 3: å»ºç«‹è¾“å…¥è¾“å‡ºæ˜ å°„å…³ç³»
        self.paired_files = []  # [(input_rel_path, output_rel_path, number_key), ...]
        missing_output = []
        input_key_seen = {}  # è®°å½•è¾“å…¥æ–‡ä»¶çš„é”®æ˜¯å¦é‡å¤
        
        for input_file in all_input_files:
            # æå–è¾“å…¥æ–‡ä»¶çš„æ•°å­—é”®
            input_basename = os.path.basename(input_file)
            number_key = extract_number_key(input_basename)
            
            # ğŸ” æ£€æµ‹è¾“å…¥é”®é‡å¤
            if number_key in input_key_seen:
                print(f"[æ•°æ®é›†] âš ï¸ è¾“å…¥é”®å†²çªï¼é”® '{number_key}' å¯¹åº”å¤šä¸ªè¾“å…¥æ–‡ä»¶:")
                print(f"[æ•°æ®é›†]       æ–‡ä»¶1: {input_key_seen[number_key]}")
                print(f"[æ•°æ®é›†]       æ–‡ä»¶2: {input_file}")
            input_key_seen[number_key] = input_file
            
            # æŸ¥æ‰¾å¯¹åº”çš„è¾“å‡ºæ–‡ä»¶
            if number_key in output_map:
                output_file = output_map[number_key]
                self.paired_files.append((input_file, output_file, number_key))
            else:
                missing_output.append((input_file, number_key))
        
        if missing_output:
            print(f"[æ•°æ®é›†] è­¦å‘Šï¼š{len(missing_output)} å¼ è¾“å…¥å›¾åƒæ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„è¾“å‡ºå›¾åƒ")
            if len(missing_output) <= 10:
                for inp, key in missing_output[:10]:
                    print(f"  - è¾“å…¥: {inp}, æ•°å­—é”®: {key}")
        
        print(f"[æ•°æ®é›†] æˆåŠŸé…å¯¹ {len(self.paired_files)} å¯¹å›¾åƒ")
        
        # ğŸ” ç»Ÿè®¡å”¯ä¸€é”®æ•°é‡
        unique_keys = set([key for _, _, key in self.paired_files])
        if len(unique_keys) < len(self.paired_files):
            print(f"[æ•°æ®é›†] âš ï¸ ä¸¥é‡è­¦å‘Šï¼šé…å¯¹çš„ {len(self.paired_files)} å¯¹å›¾åƒåªæœ‰ {len(unique_keys)} ä¸ªå”¯ä¸€é”®ï¼")
            print(f"[æ•°æ®é›†]       è¿™æ„å‘³ç€æœ‰é‡å¤çš„é”®ï¼Œä¼šå¯¼è‡´resumeåŠŸèƒ½å¤±æ•ˆï¼")
        else:
            print(f"[æ•°æ®é›†] âœ“ æ‰€æœ‰ {len(self.paired_files)} å¯¹å›¾åƒçš„é”®éƒ½æ˜¯å”¯ä¸€çš„")
        
        print(f"[æ•°æ®é›†] æ‰«æå®Œæˆï¼Œè€—æ—¶: {time.time()-scan_start:.2f}ç§’")
        
        # å¦‚æœéœ€è¦è·³è¿‡å·²å¤„ç†çš„å›¾ç‰‡
        if skip_processed and save_dir and os.path.exists(save_dir):
            print(f"[æ•°æ®é›†] å¼€å§‹æ£€æŸ¥å·²å¤„ç†æ–‡ä»¶: {save_dir}")
            check_start = time.time()
            
            # æ£€æŸ¥å·²å¤„ç†çš„æ–‡ä»¶ï¼ˆæ£€æŸ¥NPYå’ŒNPZæ ¼å¼ï¼‰
            processed_keys = set()  # ä½¿ç”¨æ•°å­—é”®è€Œä¸æ˜¯æ–‡ä»¶å
            
            # æ–¹å¼1ï¼šæ£€æŸ¥NPYæ–‡ä»¶
            with os.scandir(save_dir) as entries:
                for entry in entries:
                    if entry.is_file() and entry.name.endswith('.npy'):
                        # ä»npyæ–‡ä»¶åæå–æ•°å­—é”®
                        number_key = extract_number_key(entry.name)
                        processed_keys.add(number_key)
            
            # æ–¹å¼2ï¼šæ£€æŸ¥NPZæ–‡ä»¶ä¸­çš„sample_namesï¼ˆåŒ…æ‹¬æ‰€æœ‰run_idçš„æ–‡ä»¶ï¼‰
            npz_files = [f for f in os.listdir(save_dir) if f.startswith('batch_') and f.endswith('.npz')]
            if npz_files:
                print(f"[æ•°æ®é›†] æ‰¾åˆ° {len(npz_files)} ä¸ªNPZæ‰¹æ¬¡æ–‡ä»¶ï¼Œæ­£åœ¨è¯»å–å·²å¤„ç†æ ·æœ¬...")
            
            # è°ƒè¯•ï¼šè®°å½•è¯»å–çš„æ ·æœ¬
            loaded_samples = []
            for npz_file in npz_files:
                try:
                    npz_path = os.path.join(save_dir, npz_file)
                    npz_data = np.load(npz_path, allow_pickle=True)
                    if 'sample_names' in npz_data:
                        sample_count = len(npz_data['sample_names'])
                        for sample_name in npz_data['sample_names']:
                            # âš ï¸ å…³é”®ä¿®å¤ï¼šsample_namesä¸­å·²ç»å­˜å‚¨çš„æ˜¯number_keyï¼Œä¸è¦å†æ¬¡æå–
                            # ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²å½¢å¼ä½œä¸ºé”®
                            processed_keys.add(str(sample_name))
                            loaded_samples.append(str(sample_name))
                    npz_data.close()
                except Exception as e:
                    # å¦‚æœNPZæ–‡ä»¶æŸåï¼Œè®°å½•ä½†ç»§ç»­
                    print(f"[æ•°æ®é›†] è­¦å‘Šï¼šæ— æ³•è¯»å–NPZæ–‡ä»¶ {npz_file}: {e}")
                    pass
            
            # æ‰“å°å‰5ä¸ªå’Œå5ä¸ªå·²å¤„ç†æ ·æœ¬çš„é”®ï¼Œç”¨äºè°ƒè¯•
            if loaded_samples:
                print(f"[æ•°æ®é›†] å·²å¤„ç†æ ·æœ¬ç¤ºä¾‹ï¼ˆå‰5ä¸ªï¼‰: {loaded_samples[:5]}")
                if len(loaded_samples) > 5:
                    print(f"[æ•°æ®é›†] å·²å¤„ç†æ ·æœ¬ç¤ºä¾‹ï¼ˆå5ä¸ªï¼‰: {loaded_samples[-5:]}")
            
            print(f"[æ•°æ®é›†] æ£€æŸ¥å®Œæˆï¼Œå·²å¤„ç† {len(processed_keys)} ä¸ªæ–‡ä»¶ï¼Œè€—æ—¶: {time.time()-check_start:.2f}ç§’")
            
            # è¿‡æ»¤å‡ºæœªå¤„ç†çš„å›¾ç‰‡å¯¹
            filter_start = time.time()
            filtered_pairs = []
            skipped_samples = []  # è®°å½•è¢«è·³è¿‡çš„æ ·æœ¬ç”¨äºè°ƒè¯•
            for input_file, output_file, number_key in self.paired_files:
                if number_key not in processed_keys:
                    filtered_pairs.append((input_file, output_file, number_key))
                else:
                    skipped_samples.append(number_key)
            
            # æ‰“å°è°ƒè¯•ä¿¡æ¯
            if skipped_samples:
                print(f"[æ•°æ®é›†] è·³è¿‡å·²å¤„ç†æ ·æœ¬ç¤ºä¾‹ï¼ˆå‰5ä¸ªï¼‰: {skipped_samples[:5]}")
            if filtered_pairs:
                first_unprocessed = [key for _, _, key in filtered_pairs[:5]]
                print(f"[æ•°æ®é›†] å¾…å¤„ç†æ ·æœ¬ç¤ºä¾‹ï¼ˆå‰5ä¸ªï¼‰: {first_unprocessed}")
            
            self.paired_files = filtered_pairs
            print(f"[æ•°æ®é›†] è¿‡æ»¤å®Œæˆï¼Œè·³è¿‡: {len(skipped_samples)} å¯¹ï¼Œå¾…å¤„ç†: {len(self.paired_files)} å¯¹ï¼Œè€—æ—¶: {time.time()-filter_start:.2f}ç§’")
        
        print(f"[æ•°æ®é›†] æœ€ç»ˆå¾…å¤„ç†å›¾åƒå¯¹æ•°é‡: {len(self.paired_files)}")
    
    def __len__(self):
        return len(self.paired_files)
    
    def __getitem__(self, idx):
        input_rel_path, output_rel_path, number_key = self.paired_files[idx]
        
        # æ„å»ºå®Œæ•´è·¯å¾„
        input_image_path = os.path.join(self.input_image_path, input_rel_path)
        output_image_path = os.path.join(self.output_image_path, output_rel_path)
        
        try:
            # åŠ è½½è¾“å…¥å›¾åƒï¼ˆç”¨äºJanusæå–embeddings/masksï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œä¸åšé¢„å¤„ç†ï¼Œåªæ˜¯è®°å½•è·¯å¾„ï¼Œå®é™…åŠ è½½åœ¨batchå¤„ç†æ—¶è¿›è¡Œ
            
            # åŠ è½½è¾“å‡ºå›¾åƒï¼ˆç”¨äºautoencoderæå–momentsï¼‰
            with Image.open(output_image_path) as pil_image:
                # ç›´æ¥è½¬æ¢ä¸ºRGBï¼Œé¿å…åç»­å¤„ç†
                if pil_image.mode != "RGB":
                    pil_image = pil_image.convert("RGB")
                
                # å¤„ç†å›¾åƒ - åªå¤„ç†256å¤§å°
                image_256 = center_crop_arr(pil_image, image_size=256)
            
            # å½’ä¸€åŒ–å¹¶è½¬æ¢æ ¼å¼
            image_256 = (image_256 / 127.5 - 1.0).astype(np.float32)
            image_256 = einops.rearrange(image_256, 'h w c -> c h w')
            
            return {
                'image_256': torch.from_numpy(image_256),  # æ¥è‡ªoutput_image_pathï¼Œç”¨äºmoments
                'input_image_path': input_image_path,      # ç”¨äºembeddings/masks
                'output_image_path': output_image_path,    # ç”¨äºmoments
                'img_name': number_key,  # ä½¿ç”¨æ•°å­—é”®ä½œä¸ºæ ·æœ¬å
                'success': True
            }
        except Exception as e:
            # è¿”å›ä¸€ä¸ªå¤±è´¥æ ‡è®°
            return {
                'image_256': torch.zeros((3, 256, 256), dtype=torch.float32),
                'input_image_path': '',
                'output_image_path': '',
                'img_name': number_key,  # ä½¿ç”¨æ•°å­—é”®
                'success': False
            }


def main():
    """
    ä¸»å‡½æ•° - è‡ªåŠ¨å¢é‡å¤„ç†ï¼Œè·³è¿‡å·²å¤„ç†çš„å›¾ç‰‡
    
    é…ç½®å‚æ•°é€šè¿‡ç¯å¢ƒå˜é‡ä¼ å…¥:
        BATCH_SIZE: æ‰¹æ¬¡å¤§å° (é»˜è®¤: 1024, é’ˆå¯¹H100 80GBä¼˜åŒ–)
        INPUT_IMAGE_PATH: è¾“å…¥å›¾åƒè·¯å¾„ï¼ˆç”¨äºæå–embeddingså’Œmasksï¼‰
        OUTPUT_IMAGE_PATH: è¾“å‡ºå›¾åƒè·¯å¾„ï¼ˆç”¨äºæå–momentsï¼‰
        SAVE_DIR: ä¿å­˜ç›®å½•
        MODEL_PATH: Janusæ¨¡å‹è·¯å¾„
        AUTOENCODER_PATH: Autoencoderæ¨¡å‹è·¯å¾„
        NUM_WORKERS: DataLoaderå·¥ä½œè¿›ç¨‹æ•°
        PREFETCH_FACTOR: é¢„å–å› å­
        RECURSIVE_SCAN: æ˜¯å¦é€’å½’æ‰«æå­æ–‡ä»¶å¤¹
        TASK_PREFIX: ä»»åŠ¡å‰ç¼€ï¼ˆå¯é€‰ï¼Œæ ¼å¼: task_type__edit_methodï¼‰
                     - å¦‚æœè®¾ç½®ï¼Œè·¯å¾„ä¼šä¿å­˜ä¸ºç›¸å¯¹äºROOT_DIRçš„å®Œæ•´ç»“æ„
                     - å¦‚æœä¸è®¾ç½®ï¼Œè·¯å¾„ä¿å­˜ä¸ºç›¸å¯¹äºINPUT/OUTPUT_IMAGE_PATH
    """
    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®å‚æ•°
    bz = int(os.getenv('BATCH_SIZE', '1024'))
    input_image_path = os.getenv('INPUT_IMAGE_PATH', '/storage/v-jinpewang/lab_folder/junchao/crossflow_data/recon_data/trainset/train_00')
    output_image_path = os.getenv('OUTPUT_IMAGE_PATH', '/storage/v-jinpewang/lab_folder/junchao/crossflow_data/recon_data/trainset/train_00_output')
    save_dir = os.getenv('SAVE_DIR', '/storage/v-jinpewang/lab_folder/junchao/crossflow_data/recon_data/train_features_2D/train_00')
    model_path = os.getenv('MODEL_PATH', 'deepseek-ai/Janus-Pro-1B')
    autoencoder_path = os.getenv('AUTOENCODER_PATH', '/storage/v-jinpewang/lab_folder/qisheng_data/assets/stable-diffusion/autoencoder_kl.pth')
    num_workers = int(os.getenv('NUM_WORKERS', '16'))
    prefetch_factor = int(os.getenv('PREFETCH_FACTOR', '8'))
    recursive_scan = os.getenv('RECURSIVE_SCAN', 'true').lower() == 'true'
    task_prefix = os.getenv('TASK_PREFIX', '')  # ä»»åŠ¡å‰ç¼€ï¼Œç”¨äºåŒºåˆ†ä¸åŒä»»åŠ¡ç±»å‹å’Œç¼–è¾‘æ–¹æ³•
    # åˆå§‹åŒ–Acceleratorï¼Œæ”¯æŒå¤šGPUå¹¶è¡Œ
    accelerator = Accelerator()
    device = accelerator.device
    
    # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°ä¿¡æ¯å’Œåˆ›å»ºæ–‡ä»¶å¤¹
    if accelerator.is_main_process:
        print(f"ä½¿ç”¨ {accelerator.num_processes} ä¸ªGPUè¿›è¡Œå¹¶è¡Œå¤„ç†")
        print(f"å½“å‰è¿›ç¨‹è®¾å¤‡: {device}")
        print(f"NCCL Backend: {torch.distributed.is_nccl_available()}")
        print(f"å¢é‡å¤„ç†æ¨¡å¼ï¼šè‡ªåŠ¨è·³è¿‡å·²å¤„ç†çš„å›¾ç‰‡")
        print(f"\né…ç½®å‚æ•°:")
        print(f"  æ‰¹æ¬¡å¤§å°: {bz}")
        print(f"  è¾“å…¥å›¾åƒè·¯å¾„ï¼ˆembeddings/masksï¼‰: {input_image_path}")
        print(f"  è¾“å‡ºå›¾åƒè·¯å¾„ï¼ˆmomentsï¼‰: {output_image_path}")
        print(f"  ä¿å­˜è·¯å¾„: {save_dir}")
        if task_prefix:
            print(f"  ä»»åŠ¡æ ‡è¯†: {task_prefix}")
        print(f"  é€’å½’æ‰«æ: {recursive_scan}")
        print(f"  å·¥ä½œè¿›ç¨‹: {num_workers}")
    
    # æ‰“å°æ¯ä¸ªè¿›ç¨‹çš„ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    print(f"[Rank {accelerator.process_index}] åˆå§‹åŒ–å®Œæˆï¼Œè®¾å¤‡: {device}")
    
    # åªåœ¨ä¸»è¿›ç¨‹åˆ›å»ºä¿å­˜ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if accelerator.is_main_process:
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
            print(f"åˆ›å»ºä¿å­˜ç›®å½•: {save_dir}")
        else:
            print(f"ä¿å­˜ç›®å½•å·²å­˜åœ¨ï¼Œå°†è¿›è¡Œå¢é‡å¤„ç†: {save_dir}")
    if accelerator.is_main_process:
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸Šæ¬¡æœªå®Œæˆçš„è¿è¡Œ
        run_id_file = os.path.join(save_dir, ".current_run_id")
        if os.path.exists(run_id_file):
            # è¯»å–ä¸Šæ¬¡çš„run_id
            with open(run_id_file, "r") as f:
                old_run_id = f.read().strip()
            
            # æ£€æŸ¥ä¸Šæ¬¡è¿è¡Œæ˜¯å¦æˆåŠŸå®Œæˆ
            success_file = os.path.join(save_dir, f".run_{old_run_id}_completed")
            if os.path.exists(success_file):
                print(f"æ£€æµ‹åˆ°ä¸Šæ¬¡è¿è¡ŒID: {old_run_id} å·²æˆåŠŸå®Œæˆ")
            else:
                # ä¸Šæ¬¡è¿è¡Œæœªå®Œæˆï¼Œä½†ä¿ç•™å·²ä¿å­˜çš„å®Œæ•´NPZæ–‡ä»¶ï¼Œåªæ¸…ç†ä¸´æ—¶æ–‡ä»¶
                print(f"æ£€æµ‹åˆ°ä¸Šæ¬¡è¿è¡ŒID: {old_run_id} æœªå®Œæˆ")
                print(f"ä¿ç•™å·²ä¿å­˜çš„å®Œæ•´NPZæ–‡ä»¶ï¼Œåªæ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
                cleaned_count = 0
                kept_count = 0
                for filename in os.listdir(save_dir):
                    # åªåˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼ˆ.npz.tmpï¼‰ï¼Œä¿ç•™å®Œæ•´çš„NPZæ–‡ä»¶
                    if filename.startswith(f"batch_{old_run_id}_") and filename.endswith('.npz.tmp'):
                        tmp_path = os.path.join(save_dir, filename)
                        try:
                            os.remove(tmp_path)
                            cleaned_count += 1
                        except Exception as e:
                            print(f"è­¦å‘Šï¼šæ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {filename}: {e}")
                    # ç»Ÿè®¡ä¿ç•™çš„å®Œæ•´NPZæ–‡ä»¶
                    elif filename.startswith(f"batch_{old_run_id}_") and filename.endswith('.npz'):
                        kept_count += 1
                
                if cleaned_count > 0:
                    print(f"å·²æ¸…ç† {cleaned_count} ä¸ªä¸´æ—¶æ–‡ä»¶")
                if kept_count > 0:
                    print(f"ä¿ç•™ {kept_count} ä¸ªå®Œæ•´çš„NPZæ–‡ä»¶ï¼ˆå°†ç»§ç»­ä½¿ç”¨ï¼‰")
                if cleaned_count == 0 and kept_count == 0:
                    print(f"æœªæ‰¾åˆ°éœ€è¦æ¸…ç†çš„æ–‡ä»¶")
        
        # ç”Ÿæˆæ–°çš„run_id
        run_id = time.strftime("%Y%m%d-%H%M%S")
        print(f"æœ¬æ¬¡è¿è¡ŒID: {run_id}")
        with open(run_id_file, "w") as f:
            f.write(run_id)
    
    accelerator.wait_for_everyone()  # ç­‰å¾…ä¸»è¿›ç¨‹æ£€æŸ¥/åˆ›å»ºå®Œæ–‡ä»¶å¤¹
    
    # æ‰€æœ‰è¿›ç¨‹è¯»å–run_id
    with open(os.path.join(save_dir, ".current_run_id"), "r") as f:
        run_id = f.read().strip()
    
    # åŠ è½½æ¨¡å‹
    vl_chat_processor: VLChatProcessor = VLChatProcessor.from_pretrained(model_path)
    
    vl_gpt: MultiModalityCausalLM = AutoModelForCausalLM.from_pretrained(
        model_path, trust_remote_code=True, use_safetensors=True
    )
    vl_gpt = vl_gpt.half().eval().to(device)
    
    # åŠ è½½autoencoder
    autoencoder = libs.autoencoder.get_model(autoencoder_path)
    autoencoder.eval()
    autoencoder.requires_grad_(False)
    autoencoder = autoencoder.to(device)
    
    # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨ï¼ˆæ”¯æŒå¢é‡å¤„ç†ï¼‰
    # recursive=True: é€’å½’æ‰«æå­æ–‡ä»¶å¤¹ï¼ˆç¨æ…¢ï¼Œä½†æ”¯æŒä»»æ„ç›®å½•ç»“æ„ï¼‰
    # recursive=False: åªæ‰«æé¡¶å±‚ï¼ˆæ›´å¿«ï¼Œé€‚åˆå›¾ç‰‡éƒ½åœ¨åŒä¸€å±‚çš„æƒ…å†µï¼‰
    dataset = ImageFeatureDataset(
        input_image_path,   # ç”¨äºæå–embeddingså’Œmasks
        output_image_path,  # ç”¨äºæå–moments
        save_dir=save_dir, 
        skip_processed=True,
        recursive=recursive_scan  # ä»ç¯å¢ƒå˜é‡è¯»å–
    )
    
    # å¦‚æœæ²¡æœ‰å¾…å¤„ç†çš„æ ·æœ¬ï¼Œç›´æ¥é€€å‡º
    if len(dataset) == 0:
        if accelerator.is_main_process:
            print("æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–°å›¾ç‰‡ï¼Œç¨‹åºé€€å‡ºã€‚")
        return
    
    dataloader = DataLoader(
        dataset, 
        batch_size=bz, 
        shuffle=False,
        num_workers=num_workers,  # ä»ç¯å¢ƒå˜é‡è¯»å–
        pin_memory=True,
        persistent_workers=True,  # ä¿æŒworkerè¿›ç¨‹ï¼Œå‡å°‘åˆ›å»ºé”€æ¯å¼€é”€
        prefetch_factor=prefetch_factor  # ä»ç¯å¢ƒå˜é‡è¯»å–
    )
    
    if accelerator.is_main_process:
        print(f"æ€»æ ·æœ¬æ•°: {len(dataset)}")
        print(f"æ¯ä¸ªGPUæ‰¹æ¬¡å¤§å°: {bz}")
        print(f"æ€»æ‰¹æ¬¡æ•°: {len(dataloader)}")
    
    # ä½¿ç”¨acceleratorå‡†å¤‡æ•°æ®åŠ è½½å™¨ï¼ˆæ¨¡å‹å·²ç»æ‰‹åŠ¨ç§»åˆ°è®¾å¤‡ä¸Šï¼‰
    # æ³¨æ„ï¼šå¯¹äºæ¨ç†ä»»åŠ¡ï¼Œä¸éœ€è¦ç”¨DDPåŒ…è£…æ¨¡å‹ï¼Œåªéœ€è¦åˆ†å¸ƒå¼çš„dataloader
    dataloader = accelerator.prepare(dataloader)
    
    # æ¨ç†ä»»åŠ¡ç›´æ¥ä½¿ç”¨æ¨¡å‹ï¼Œä¸éœ€è¦unwrap
    unwrapped_vl_gpt = vl_gpt
    
    idx = 0
    failed_samples = []
    processing_error = False  # ç”¨äºæ ‡è®°æ˜¯å¦å‘ç”Ÿé”™è¯¯
    
    # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦ï¼ˆåªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºï¼‰
    if accelerator.is_main_process:
        progress_bar = tqdm(total=len(dataloader), desc="å¤„ç†æ‰¹æ¬¡")
    
    # åœ¨å¼€å§‹å¤„ç†å‰ï¼Œç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½å‡†å¤‡å¥½äº†
    if accelerator.is_main_process:
        print(f"\n[ä¸»è¿›ç¨‹] å¼€å§‹å¤„ç†ï¼Œç­‰å¾…æ‰€æœ‰è¿›ç¨‹å‡†å¤‡...")
    accelerator.wait_for_everyone()
    if accelerator.is_main_process:
        print(f"[ä¸»è¿›ç¨‹] æ‰€æœ‰è¿›ç¨‹å·²å°±ç»ªï¼Œå¼€å§‹å¤„ç†æ‰¹æ¬¡\n")
    
    # æ•´ä¸ªæ¨ç†è¿‡ç¨‹ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼Œé¿å…å†…å­˜æ³„æ¼
    with torch.no_grad():
        try:
            for batch_idx, batch in enumerate(dataloader):
                # è®°å½•æ¯ä¸ªæ‰¹æ¬¡çš„å¼€å§‹æ—¶é—´
                batch_start_time = time.time()
                
                # æ¯ä¸ªæ‰¹æ¬¡å¼€å§‹æ—¶æ‰“å°è¿›ç¨‹ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
                if batch_idx % 5 == 0:
                    print(f"[Rank {accelerator.process_index}] å¼€å§‹å¤„ç†æ‰¹æ¬¡ {batch_idx}")
                
                # è®°å½•å¤±è´¥çš„æ ·æœ¬
                success_list = batch['success'].tolist()

                failed_names = [n for n, v in zip(batch['img_name'], success_list) if not v]
                if failed_names:
                    failed_samples.extend(failed_names)

                # åªå¤„ç†æˆåŠŸæ ·æœ¬
                valid_mask = torch.tensor(success_list, dtype=torch.bool, device=batch['success'].device)

                batch_img_256 = batch['image_256'][valid_mask].to(device, non_blocking=True)
                batch_input_image_paths  = [p for p, v in zip(batch['input_image_path'],  success_list) if v]
                batch_output_image_paths = [p for p, v in zip(batch['output_image_path'], success_list) if v]
                batch_names              = [n for n, v in zip(batch['img_name'],          success_list) if v]
                
                # è®¡ç®—è¾“å…¥å›¾åƒç›¸å¯¹è·¯å¾„ï¼ˆåŒ…å«å®Œæ•´çš„ä»»åŠ¡ç»“æ„ï¼‰
                # æ ¼å¼ï¼štask_type/edit_method/input/relative_path
                batch_input_relative_paths = []
                for img_path in batch_input_image_paths:
                    try:
                        if task_prefix and '__' in task_prefix:
                            task_type, edit_method = task_prefix.split('__', 1)
                            # æå–ç›¸å¯¹äºinputç›®å½•çš„è·¯å¾„
                            rel_to_input = os.path.relpath(img_path, input_image_path)
                            # ç»„åˆå®Œæ•´è·¯å¾„ï¼štask_type/edit_method/input/rel_path
                            full_rel_path = os.path.join(task_type, edit_method, 'input', rel_to_input)
                            batch_input_relative_paths.append(full_rel_path)
                        else:
                            # å›é€€åˆ°åŸé€»è¾‘ï¼ˆä¸å¸¦ä»»åŠ¡å‰ç¼€ï¼‰
                            rel_path = os.path.relpath(img_path, input_image_path)
                            batch_input_relative_paths.append(rel_path)
                    except:
                        batch_input_relative_paths.append(os.path.basename(img_path))
                
                # è®¡ç®—è¾“å‡ºå›¾åƒç›¸å¯¹è·¯å¾„ï¼ˆåŒ…å«å®Œæ•´çš„ä»»åŠ¡ç»“æ„ï¼‰
                # æ ¼å¼ï¼štask_type/edit_method/output/relative_path
                batch_output_relative_paths = []
                for img_path in batch_output_image_paths:
                    try:
                        if task_prefix and '__' in task_prefix:
                            task_type, edit_method = task_prefix.split('__', 1)
                            # æå–ç›¸å¯¹äºoutputç›®å½•çš„è·¯å¾„
                            rel_to_output = os.path.relpath(img_path, output_image_path)
                            # ç»„åˆå®Œæ•´è·¯å¾„ï¼štask_type/edit_method/output/rel_path
                            full_rel_path = os.path.join(task_type, edit_method, 'output', rel_to_output)
                            batch_output_relative_paths.append(full_rel_path)
                        else:
                            # å›é€€åˆ°åŸé€»è¾‘ï¼ˆä¸å¸¦ä»»åŠ¡å‰ç¼€ï¼‰
                            rel_path = os.path.relpath(img_path, output_image_path)
                            batch_output_relative_paths.append(rel_path)
                    except:
                        batch_output_relative_paths.append(os.path.basename(img_path))
                
                # ç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½èµ°ç›¸åŒçš„ä»£ç è·¯å¾„
                if len(batch_names) == 0:
                    # ç¡®ä¿CUDAæ“ä½œå®Œæˆ
                    if torch.cuda.is_available():
                        torch.cuda.synchronize()
                    
                    # æ›´æ–°è¿›åº¦æ¡ä½†ä¸æå‰continueï¼Œä¿æŒæ‰€æœ‰è¿›ç¨‹åŒæ­¥
                    if accelerator.is_main_process:
                        progress_bar.update(1)
                    
                    # æ·»åŠ åŒæ­¥ç‚¹ï¼Œç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½åˆ°è¾¾è¿™é‡Œ
                    print(f"[Rank {accelerator.process_index}] æ‰¹æ¬¡ {batch_idx} æ— æœ‰æ•ˆæ ·æœ¬ï¼Œç­‰å¾…åŒæ­¥")
                    accelerator.wait_for_everyone()
                    continue
                
                # å¤„ç†Janus embeddings - æ‰¹é‡å¤„ç†ç‰ˆæœ¬
                batch_embeddings = []
                batch_attention_masks = []
                
                # æ‰“å°å½“å‰æ‰¹æ¬¡çš„æ ·æœ¬æ•°ï¼ˆè°ƒè¯•ç”¨ï¼‰
                if batch_idx % 5 == 0:
                    print(f"[Rank {accelerator.process_index}] æ‰¹æ¬¡ {batch_idx} æœ‰ {len(batch_input_image_paths)} ä¸ªæœ‰æ•ˆæ ·æœ¬ï¼Œå¼€å§‹æ‰¹é‡å¤„ç†Janus...")
                
                # è®°å½•Januså¤„ç†æ—¶é—´
                janus_start_time = time.time()
                
                try:
                    # çœŸæ­£çš„æ‰¹é‡å¤„ç† - ä¸€æ¬¡æ€§åŠ è½½å’Œé¢„å¤„ç†æ‰€æœ‰å›¾åƒ
                    question = ""
                    
                    # Step 1: æ‰¹é‡åŠ è½½æ‰€æœ‰PILå›¾åƒï¼ˆå¹¶è¡ŒI/Oï¼‰- ä»input_image_pathåŠ è½½
                    load_start = time.time()
                    all_pil_images = []
                    for image_path in batch_input_image_paths:
                        try:
                            pil_img = Image.open(image_path).convert('RGB')
                            all_pil_images.append(pil_img)
                        except Exception as e:
                            print(f"[Rank {accelerator.process_index}] è­¦å‘Šï¼šåŠ è½½è¾“å…¥å›¾åƒå¤±è´¥ {image_path}: {e}")
                            # åˆ›å»ºä¸€ä¸ªç©ºç™½å›¾åƒä½œä¸ºå ä½
                            all_pil_images.append(Image.new('RGB', (384, 384), color='black'))
                    load_time = time.time() - load_start
                    
                    # Step 2: æ‰¹é‡å›¾åƒé¢„å¤„ç†ï¼ˆä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰å›¾åƒï¼‰
                    preprocess_start = time.time()
                    images_outputs = vl_chat_processor.image_processor(all_pil_images, return_tensors="pt")
                    batched_pixel_values = images_outputs.pixel_values.to(device)  # [batch_size, 3, H, W]
                    preprocess_time = time.time() - preprocess_start
                    
                    # Step 3: å‡†å¤‡æ‰¹é‡è¾“å…¥ï¼ˆæ–‡æœ¬éƒ¨åˆ†ï¼‰
                    text_start = time.time()
                    # åˆ›å»ºç»Ÿä¸€çš„conversationæ ¼å¼ï¼ˆæ‰€æœ‰å›¾åƒä½¿ç”¨ç›¸åŒçš„promptï¼‰
                    sft_format = vl_chat_processor.apply_sft_template_for_multi_turn_prompts(
                        conversations=[
                            {"role": "<|User|>", "content": f"<image_placeholder>\n{question}"},
                            {"role": "<|Assistant|>", "content": ""},
                        ],
                        sft_format=vl_chat_processor.sft_format,
                        system_prompt=vl_chat_processor.system_prompt,
                    )
                    
                    # tokenizeï¼ˆæ‰€æœ‰æ ·æœ¬ä½¿ç”¨ç›¸åŒçš„tokenï¼‰
                    input_ids = vl_chat_processor.tokenizer.encode(sft_format)
                    input_ids = torch.LongTensor(input_ids)
                    
                    # ä¸ºæ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ ·æœ¬å¤åˆ¶input_ids
                    batch_size = len(all_pil_images)
                    batched_input_ids = input_ids.unsqueeze(0).repeat(batch_size, 1)  # [batch_size, seq_len]
                    batched_attention_mask = torch.ones_like(batched_input_ids)
                    
                    # åˆ›å»ºimage masks
                    image_token_mask = batched_input_ids == vl_chat_processor.image_id
                    batched_images_seq_mask = image_token_mask
                    
                    # å‡è®¾æ¯ä¸ªå›¾åƒæœ‰576ä¸ªtokenï¼ˆæ ¹æ®Janusçš„é…ç½®ï¼‰
                    num_image_tokens = 576
                    batched_images_emb_mask = torch.zeros((batch_size, 1, num_image_tokens)).bool()
                    batched_images_emb_mask[:, :, :num_image_tokens] = True
                    
                    # è°ƒæ•´pixel_valueså½¢çŠ¶ä»¥åŒ¹é…æœŸæœ›çš„ [batch_size, n_images, 3, H, W]
                    batched_pixel_values = batched_pixel_values.unsqueeze(1)  # [batch_size, 1, 3, H, W]
                    
                    text_time = time.time() - text_start
                    
                    # Step 4: æ‰¹é‡ç¼–ç 
                    encode_start = time.time()
                    with torch.no_grad():
                        inputs_embeds = unwrapped_vl_gpt.prepare_inputs_embeds(
                            input_ids=batched_input_ids.to(device),
                            pixel_values=batched_pixel_values,
                            images_seq_mask=batched_images_seq_mask.to(device),
                            images_emb_mask=batched_images_emb_mask.to(device)
                        )
                    encode_time = time.time() - encode_start
                    
                    # æ‰“å°è¯¦ç»†çš„æ—¶é—´åˆ†è§£
                    if batch_idx % 5 == 0:
                        total_prep = load_time + preprocess_time + text_time
                        print(f"[Rank {accelerator.process_index}] æ—¶é—´åˆ†è§£ - å›¾åƒåŠ è½½: {load_time:.2f}s, é¢„å¤„ç†: {preprocess_time:.2f}s, æ–‡æœ¬: {text_time:.3f}s, ç¼–ç : {encode_time:.2f}s")
                        print(f"[Rank {accelerator.process_index}] æ‰¹é‡å½¢çŠ¶ - pixel_values: {batched_pixel_values.shape}, inputs_embeds: {inputs_embeds.shape}")
                    
                    # inputs_embeds.shape: [batch_size, 576, 2048]
                    # æ‰¹é‡è½¬æ¢åˆ°CPUï¼ˆæ¯”é€ä¸ªè½¬æ¢å¿«å¾—å¤šï¼‰
                    inputs_embeds_cpu = inputs_embeds.detach().cpu().float().numpy()
                    
                    # å°†æ‰¹é‡ç»“æœæ‹†åˆ†ä¸ºå•ä¸ªæ ·æœ¬
                    for i in range(inputs_embeds_cpu.shape[0]):
                        final_tensor = inputs_embeds_cpu[i]  # [576, 2048]
                        batch_embeddings.append(final_tensor)
                        attention_mask = [1] * 576
                        batch_attention_masks.append(attention_mask)
                    
                    janus_time = time.time() - janus_start_time
                    if batch_idx % 5 == 0:
                        print(f"[Rank {accelerator.process_index}] æ‰¹æ¬¡ {batch_idx} Janusæ‰¹é‡å¤„ç†è€—æ—¶: {janus_time:.2f}ç§’ (å¹³å‡ {janus_time/len(batch_input_image_paths):.3f}ç§’/å¼ )")
                
                except Exception as e:
                    # å¦‚æœæ‰¹é‡å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°é€ä¸ªå¤„ç†
                    print(f"[Rank {accelerator.process_index}] è­¦å‘Šï¼šæ‰¹æ¬¡ {batch_idx} æ‰¹é‡å¤„ç†å¤±è´¥: {e}ï¼Œå›é€€åˆ°é€ä¸ªå¤„ç†")
                    import traceback
                    traceback.print_exc()
                    
                    batch_embeddings = []
                    batch_attention_masks = []
                    question = ""
                    
                    for img_idx, image_path in enumerate(batch_input_image_paths):
                        try:
                            conversation = [
                                {
                                    "role": "<|User|>",
                                    "content": f"<image_placeholder>\n{question}",
                                    "images": [image_path],
                                },
                                {"role": "<|Assistant|>", "content": ""},
                            ]
                            
                            pil_images = load_pil_images(conversation)
                            prepare_inputs = vl_chat_processor(
                                conversations=conversation, images=pil_images, force_batchify=True
                            ).to(device)
                            
                            with torch.no_grad():
                                inputs_embeds = unwrapped_vl_gpt.prepare_inputs_embeds(**prepare_inputs)
                            
                            final_tensor = inputs_embeds.squeeze(dim=0)
                            batch_embeddings.append(final_tensor.detach().cpu().float().numpy())
                            attention_mask = [1] * 576
                            batch_attention_masks.append(attention_mask)
                        
                        except Exception as e2:
                            print(f"[Rank {accelerator.process_index}] é”™è¯¯ï¼šæ ·æœ¬ {img_idx} å¤„ç†å¤±è´¥: {e2}")
                            batch_embeddings.append(np.zeros((576, 2048), dtype=np.float32))
                            batch_attention_masks.append([1] * 576)
                    
                    if torch.cuda.is_available():
                        torch.cuda.synchronize()
                    
                    janus_time = time.time() - janus_start_time
                    if batch_idx % 5 == 0:
                        print(f"[Rank {accelerator.process_index}] æ‰¹æ¬¡ {batch_idx} Janusé€ä¸ªå¤„ç†è€—æ—¶: {janus_time:.2f}ç§’")
                
                # è®°å½•Autoencoderå¤„ç†æ—¶é—´
                autoencoder_start_time = time.time()
                
                # å¤„ç†autoencoderç¼–ç  - åªå¤„ç†256
                with torch.no_grad():
                    moments_256 = autoencoder(batch_img_256, fn='encode_moments')
                    if moments_256.dim() > 3:
                        moments_256 = moments_256.squeeze(0)
                    moments_256 = moments_256.detach().cpu().numpy()
                
                # ç¡®ä¿CUDAæ“ä½œå®Œæˆï¼Œé¿å…å¼‚æ­¥æ“ä½œå¯¼è‡´çš„é—®é¢˜
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                
                autoencoder_time = time.time() - autoencoder_start_time
                if batch_idx % 5 == 0:
                    print(f"[Rank {accelerator.process_index}] æ‰¹æ¬¡ {batch_idx} Autoencoderå¤„ç†è€—æ—¶: {autoencoder_time:.2f}ç§’")
                
                # ä¿å­˜ç‰¹å¾ - æ‰¹é‡ä¿å­˜npzä¼˜åŒ–ç‰ˆï¼ˆ2D VAEæ ¼å¼ï¼‰
                save_start = time.time()
                
                process_id = accelerator.process_index
                saved_count = 0
                
                # ç­–ç•¥ï¼šå…ˆæ‰¹é‡ä¿å­˜npzï¼ˆæå¿«ï¼‰ï¼Œåç»­å¯ä»¥ç”¨å•ç‹¬è„šæœ¬è½¬æ¢å›npy
                # å¦‚æœæœ‰task_prefixï¼Œæ·»åŠ åˆ°æ–‡ä»¶åä¸­
                if task_prefix:
                    batch_file = os.path.join(save_dir, f"batch_{task_prefix}_{run_id}_{batch_idx:06d}_rank{process_id}.npz")
                else:
                    batch_file = os.path.join(save_dir, f"batch_{run_id}_{batch_idx:06d}_rank{process_id}.npz")

                # å‡†å¤‡æ‰¹é‡æ•°æ®ï¼ˆ2D VAEæ ¼å¼ï¼Œä¸dataset.pyå…¼å®¹ï¼‰
                llm_type = 't5'  # ä¸é…ç½®æ–‡ä»¶ä¿æŒä¸€è‡´
                batch_data = {
                    'sample_names': [str(name) for name in batch_names],  # ç¡®ä¿éƒ½æ˜¯å­—ç¬¦ä¸²
                    'input_image_relative_paths': [str(path) for path in batch_input_relative_paths],
                    'output_image_relative_paths': [str(path) for path in batch_output_relative_paths],
                    'vae_type': '2D',
                    'llm': llm_type,
                    'resolution': 256,
                }
                
                # ğŸ” æ£€æŸ¥å½“å‰æ‰¹æ¬¡å†…éƒ¨æ˜¯å¦æœ‰é‡å¤é”®
                if len(batch_names) != len(set(batch_names)):
                    duplicates_in_batch = [name for name in set(batch_names) if batch_names.count(name) > 1]
                    print(f"[Rank {process_id}] âš ï¸ è­¦å‘Šï¼šæ‰¹æ¬¡ {batch_idx} å†…éƒ¨æœ‰é‡å¤é”®ï¼")
                    print(f"[Rank {process_id}]       é‡å¤é”®: {duplicates_in_batch[:5]}")
                
                # è°ƒè¯•ï¼šæ‰“å°ä¿å­˜çš„æ ·æœ¬é”®
                if batch_idx % 10 == 0 and len(batch_names) > 0:
                    print(f"[Rank {process_id}] æ‰¹æ¬¡ {batch_idx} ä¿å­˜æ ·æœ¬é”®ç¤ºä¾‹: {batch_names[:3]}")
                
                # ğŸ” é¢å¤–éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦æœ‰é‡å¤ï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹ï¼‰
                if batch_idx == 0 and accelerator.is_main_process:
                    # è¯»å–æ‰€æœ‰å·²æœ‰çš„NPZæ–‡ä»¶ä¸­çš„æ ·æœ¬å
                    existing_samples = set()
                    for existing_npz in os.listdir(save_dir):
                        if existing_npz.startswith('batch_') and existing_npz.endswith('.npz'):
                            try:
                                with np.load(os.path.join(save_dir, existing_npz), allow_pickle=True) as existing_data:
                                    if 'sample_names' in existing_data:
                                        existing_samples.update([str(s) for s in existing_data['sample_names']])
                            except:
                                pass
                    
                    # æ£€æŸ¥å½“å‰æ‰¹æ¬¡æ˜¯å¦æœ‰é‡å¤
                    current_samples = set([str(name) for name in batch_names])
                    duplicates = current_samples & existing_samples
                    if duplicates:
                        print(f"[è­¦å‘Š] æ£€æµ‹åˆ°é‡å¤æ ·æœ¬ï¼å½“å‰æ‰¹æ¬¡æœ‰ {len(duplicates)} ä¸ªæ ·æœ¬å·²å­˜åœ¨:")
                        print(f"  é‡å¤æ ·æœ¬ç¤ºä¾‹: {list(duplicates)[:5]}")
                    else:
                        print(f"[éªŒè¯] âœ“ ç¬¬ä¸€ä¸ªæ‰¹æ¬¡æ— é‡å¤æ ·æœ¬ï¼ˆå½“å‰{len(current_samples)}ä¸ªï¼Œå·²å­˜åœ¨{len(existing_samples)}ä¸ªï¼‰")
                
                # å¦‚æœæœ‰task_prefixï¼Œè§£æå¹¶æ·»åŠ åˆ°batch_dataä¸­
                if task_prefix and '__' in task_prefix:
                    task_type, edit_method = task_prefix.split('__', 1)
                    batch_data['task_type'] = task_type
                    batch_data['edit_method'] = edit_method

                # æ”¶é›†æ‰€æœ‰æ•°æ®
                all_moments = []
                all_embeddings = []
                all_masks = []
                for mt_256, te_t, tm_t in zip(moments_256, batch_embeddings, batch_attention_masks):
                    all_moments.append(mt_256)
                    all_embeddings.append(te_t)
                    all_masks.append(np.array(tm_t))

                # å †å ä¸ºæ•°ç»„
                batch_data['moments'] = np.stack(all_moments)      # [batch_size, 8, 32, 32]
                batch_data['embeddings'] = np.stack(all_embeddings)  # [batch_size, 576, 2048]
                batch_data['masks'] = np.stack(all_masks)

                try:
                    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨ä¸”å¯å†™
                    if not os.path.exists(save_dir):
                        os.makedirs(save_dir, exist_ok=True)
                        print(f"[Rank {process_id}] åˆ›å»ºä¿å­˜ç›®å½•: {save_dir}")
                    
                    # è®¡ç®—æ•°æ®å¤§å°
                    estimated_size_mb = (
                        batch_data['moments'].nbytes + 
                        batch_data['embeddings'].nbytes + 
                        batch_data['masks'].nbytes
                    ) / (1024 * 1024)
                    
                    if batch_idx % 5 == 0:
                        print(f"[Rank {process_id}] æ‰¹æ¬¡ {batch_idx} æ•°æ®å¤§å°: {estimated_size_mb:.1f}MB")
                    
                    # ç›´æ¥ä¿å­˜æœ€ç»ˆæ–‡ä»¶ï¼ˆä¸ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ï¼Œä¸å‹ç¼©ï¼‰
                    try:
                        np.savez(batch_file, **batch_data)  # ä¸å‹ç¼©
                    except Exception as save_err:
                        print(f"[Rank {process_id}] np.savez å¤±è´¥: {save_err}")
                        raise
                    
                    # ç­‰å¾…æ–‡ä»¶ç³»ç»ŸåŒæ­¥
                    max_retries = 10
                    retry_delay = 0.5  # ç§’
                    for retry in range(max_retries):
                        if os.path.exists(batch_file):
                            # éªŒè¯æ–‡ä»¶å¤§å°æ˜¯å¦åˆç†ï¼ˆè‡³å°‘åº”è¯¥æœ‰å‡ MBï¼‰
                            file_size = os.path.getsize(batch_file)
                            if file_size > 1024 * 1024:  # è‡³å°‘1MB
                                break
                            else:
                                print(f"[Rank {process_id}] æ–‡ä»¶å¤§å°å¼‚å¸¸: {file_size} bytesï¼Œç­‰å¾…åŒæ­¥...")
                        
                        if retry < max_retries - 1:
                            time.sleep(retry_delay)
                        else:
                            raise FileNotFoundError(
                                f"æ–‡ä»¶åˆ›å»ºå¤±è´¥æˆ–æ–‡ä»¶å¤§å°å¼‚å¸¸: {batch_file}, "
                                f"ç­‰å¾…{max_retries * retry_delay}ç§’åä»æœªæˆåŠŸ"
                            )

                    saved_count = len(batch_names)
                    idx += saved_count

                    if batch_idx % 5 == 0:
                        file_size_mb = os.path.getsize(batch_file) / (1024 * 1024)
                        print(f"[Rank {process_id}] æ‰¹æ¬¡ {batch_idx} æ‰¹é‡ä¿å­˜æˆåŠŸï¼Œæ–‡ä»¶: {os.path.basename(batch_file)}, å¤§å°: {file_size_mb:.1f}MB")
                except Exception as e:
                    print(f'[Rank {process_id}] æ‰¹é‡ä¿å­˜å¤±è´¥: {e}')
                    print(f'[Rank {process_id}] ä¿å­˜ç›®å½•: {save_dir}')
                    print(f'[Rank {process_id}] ç›®æ ‡æ–‡ä»¶: {batch_file}')
                    print(f'[Rank {process_id}] ä¿å­˜ç›®å½•æ˜¯å¦å­˜åœ¨: {os.path.exists(save_dir)}')
                    print(f'[Rank {process_id}] ä¿å­˜ç›®å½•æ˜¯å¦å¯å†™: {os.access(save_dir, os.W_OK) if os.path.exists(save_dir) else "N/A"}')
                    
                    # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶çŠ¶æ€
                    if os.path.exists(batch_file):
                        try:
                            file_size = os.path.getsize(batch_file)
                            print(f'[Rank {process_id}] æ–‡ä»¶å·²å­˜åœ¨ï¼Œå¤§å°: {file_size} bytes')
                        except:
                            print(f'[Rank {process_id}] æ–‡ä»¶å·²å­˜åœ¨ä½†æ— æ³•è·å–å¤§å°')
                    else:
                        print(f'[Rank {process_id}] æ–‡ä»¶ä¸å­˜åœ¨')
                    
                    # æ£€æŸ¥ç£ç›˜ç©ºé—´ï¼ˆç½‘ç»œå­˜å‚¨å¯èƒ½è¿”å›0ï¼‰
                    try:
                        stat = shutil.disk_usage(save_dir if os.path.exists(save_dir) else os.path.dirname(save_dir))
                        print(f'[Rank {process_id}] ç£ç›˜ç©ºé—´ - æ€»è®¡: {stat.total/(1024**3):.2f}GB, å·²ç”¨: {stat.used/(1024**3):.2f}GB, å‰©ä½™: {stat.free/(1024**3):.2f}GB')
                        if stat.total == 0:
                            print(f'[Rank {process_id}] æ³¨æ„ï¼šè¿™å¯èƒ½æ˜¯ç½‘ç»œå­˜å‚¨/äº‘ç›˜ï¼Œæ˜¾ç¤ºç©ºé—´ä¸º0æ˜¯æ­£å¸¸çš„')
                    except Exception as disk_err:
                        print(f'[Rank {process_id}] æ— æ³•è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯: {disk_err}')
                    
                    import traceback
                    traceback.print_exc()

                
                save_time = time.time() - save_start
                if batch_idx % 5 == 0:
                    if save_time > 0.01:
                        speedup = 105.0 / save_time
                        print(f"[Rank {accelerator.process_index}] æ‰¹æ¬¡ {batch_idx} æ–‡ä»¶ä¿å­˜è€—æ—¶: {save_time:.2f}ç§’ (æé€Ÿçº¦{speedup:.1f}x)")
                    else:
                        print(f"[Rank {accelerator.process_index}] æ‰¹æ¬¡ {batch_idx} æ–‡ä»¶ä¿å­˜è€—æ—¶: {save_time:.2f}ç§’ (æå¿«ï¼)")
                
                # æ‰“å°æ‰¹æ¬¡å®Œæˆä¿¡æ¯å’Œæ€»è€—æ—¶
                batch_total_time = time.time() - batch_start_time
                if batch_idx % 5 == 0:
                    print(f"[Rank {accelerator.process_index}] æ‰¹æ¬¡ {batch_idx} å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {batch_total_time:.2f}ç§’")
                
                # å¦‚æœæŸä¸ªæ‰¹æ¬¡è€—æ—¶è¿‡é•¿ï¼Œæ‰“å°è­¦å‘Š
                if batch_total_time > 300:  # 5åˆ†é’Ÿ
                    print(f"[Rank {accelerator.process_index}] è­¦å‘Šï¼šæ‰¹æ¬¡ {batch_idx} è€—æ—¶è¿‡é•¿ ({batch_total_time:.2f}ç§’)")
                
                # æ›´æ–°è¿›åº¦æ¡
                if accelerator.is_main_process:
                    progress_bar.update(1)
                
                # æ¯éš”ä¸€å®šæ‰¹æ¬¡æ·»åŠ åŒæ­¥ç‚¹ï¼Œé˜²æ­¢è¿›ç¨‹é—´å·®è·è¿‡å¤§
                # ä½¿ç”¨ä¸­ç­‰åŒæ­¥é¢‘ç‡å¹³è¡¡æ€§èƒ½å’Œå®‰å…¨æ€§ï¼ˆæ¯10æ‰¹æ¬¡åŒæ­¥ä¸€æ¬¡ï¼‰
                # è¿‡äºé¢‘ç¹ä¼šå½±å“æ€§èƒ½ï¼Œè¿‡äºç¨€ç–å¯èƒ½å¯¼è‡´hangæ£€æµ‹å»¶è¿Ÿ
                if (batch_idx + 1) % 10 == 0:
                    # å…ˆç¡®ä¿æœ¬è¿›ç¨‹çš„CUDAæ“ä½œå®Œæˆ
                    if torch.cuda.is_available():
                        torch.cuda.synchronize()
                    
                    # æ¯ä¸ªè¿›ç¨‹éƒ½æ‰“å°åˆ°è¾¾åŒæ­¥ç‚¹çš„ä¿¡æ¯
                    sync_time = time.time()
                    print(f"[Rank {accelerator.process_index}] â± [{time.strftime('%H:%M:%S')}] åˆ°è¾¾åŒæ­¥ç‚¹ï¼Œæ‰¹æ¬¡ {batch_idx + 1}/{len(dataloader)}ï¼Œå·²ä¿å­˜ {idx} ä¸ªæ–‡ä»¶")
                    
                    if accelerator.is_main_process:
                        print(f"\n[åŒæ­¥æ£€æŸ¥ç‚¹] å·²å®Œæˆ {batch_idx + 1}/{len(dataloader)} æ‰¹æ¬¡ï¼Œæ‰€æœ‰è¿›ç¨‹å‡†å¤‡åŒæ­¥...")
                    
                    # æ·»åŠ åŒæ­¥è¶…æ—¶ä¿æŠ¤
                    try:
                        # æ‰€æœ‰è¿›ç¨‹åŒæ­¥
                        accelerator.wait_for_everyone()
                        sync_duration = time.time() - sync_time
                        
                        if accelerator.is_main_process:
                            print(f"[åŒæ­¥å®Œæˆ] æ‰€æœ‰è¿›ç¨‹å·²åŒæ­¥åˆ°æ‰¹æ¬¡ {batch_idx + 1}ï¼ŒåŒæ­¥è€—æ—¶: {sync_duration:.2f}ç§’\n")
                        
                        # åŒæ­¥åæ¸…ç†CUDAç¼“å­˜ï¼Œé˜²æ­¢å†…å­˜ç¢ç‰‡
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                    
                    except Exception as sync_error:
                        print(f"[Rank {accelerator.process_index}] åŒæ­¥å¤±è´¥: {sync_error}")
                        raise
    
        except Exception as e:
            # æ•è·å¼‚å¸¸ï¼Œç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½èƒ½æ­£ç¡®é€€å‡º
            processing_error = True
            print(f"\n[Rank {accelerator.process_index}] å‘ç”Ÿå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            
            # é‡è¦ï¼šå³ä½¿å‘ç”Ÿå¼‚å¸¸ï¼Œä¹Ÿè¦å°è¯•é€šçŸ¥å…¶ä»–è¿›ç¨‹
            # é¿å…å…¶ä»–è¿›ç¨‹æ°¸è¿œç­‰å¾…åœ¨åŒæ­¥ç‚¹
            try:
                # ç­‰å¾…å…¶ä»–è¿›ç¨‹ï¼ˆè®©å®ƒä»¬ä¹Ÿæœ‰æœºä¼šæ£€æµ‹åˆ°é—®é¢˜ï¼‰
                print(f"[Rank {accelerator.process_index}] å°è¯•é€šçŸ¥å…¶ä»–è¿›ç¨‹...")
                accelerator.wait_for_everyone()
            except Exception as sync_err:
                print(f"[Rank {accelerator.process_index}] åŒæ­¥å¤±è´¥ï¼ˆé¢„æœŸè¡Œä¸ºï¼‰: {sync_err}")
        
        finally:
            # å…³é—­è¿›åº¦æ¡
            if accelerator.is_main_process:
                progress_bar.close()
                print(f"\n[ä¸»è¿›ç¨‹] æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œç­‰å¾…å…¶ä»–è¿›ç¨‹...")
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆå¤„ç†
    accelerator.wait_for_everyone()
    
    # å¦‚æœå‘ç”Ÿé”™è¯¯ï¼Œæå‰é€€å‡º
    if processing_error:
        if accelerator.is_main_process:
            print(f"[é”™è¯¯] ç”±äºå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œç¨‹åºæå‰é€€å‡º")
        return
    
    if accelerator.is_main_process:
        print(f"[ä¸»è¿›ç¨‹] æ‰€æœ‰è¿›ç¨‹å·²å®Œæˆï¼Œå¼€å§‹æ”¶é›†ç»Ÿè®¡ä¿¡æ¯...")
    
    # æ±‡æ€»æ‰€æœ‰è¿›ç¨‹çš„ç»Ÿè®¡ä¿¡æ¯
    all_idx = accelerator.gather(torch.tensor([idx], device=device))
    
    # æ”¶é›†å¤±è´¥æ ·æœ¬åˆ—è¡¨
    all_failed_lists = gather_object([failed_samples])
    
    # è·å–æºç›®å½•çš„æ€»å›¾ç‰‡æ•°ï¼ˆåœ¨ä¸»è¿›ç¨‹å¤–è®¡ç®—ï¼Œæ‰€æœ‰è¿›ç¨‹éƒ½éœ€è¦è¿™ä¸ªä¿¡æ¯ï¼‰
    # è·å–æºç›®å½•çš„æ€»å›¾ç‰‡æ•°ï¼ˆä¸é€’å½’æ‰«æä¿æŒä¸€è‡´ï¼‰
    def _count_images(root, recursive):
        exts = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
        if recursive:
            cnt = 0
            for r, _, files in os.walk(root):
                cnt += sum(os.path.splitext(n)[1].lower() in exts for n in files)
            return cnt
        else:
            return sum(os.path.splitext(n)[1].lower() in exts for n in os.listdir(root))

    total_source_images = _count_images(input_image_path, recursive_scan)
    
    # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°ç»Ÿè®¡ä¿¡æ¯å’Œä¿å­˜å¤±è´¥åˆ—è¡¨
    if accelerator.is_main_process:
        # æ±‡æ€»æˆåŠŸå¤„ç†çš„æ–‡ä»¶æ•°
        total_saved = all_idx.sum().item()
        print(f'\n==================')
        print(f'å¤„ç†å®Œæˆï¼')
        print(f'æˆåŠŸä¿å­˜: {total_saved} ä¸ªæ–‡ä»¶')
        print(f'å„è¿›ç¨‹å¤„ç†æ•°é‡: {all_idx.cpu().tolist()}')
        
        # åˆå¹¶æ‰€æœ‰è¿›ç¨‹çš„å¤±è´¥æ ·æœ¬ï¼ˆå»é‡ï¼‰
        all_failed = []
        if all_failed_lists:
            for proc_failed_list in all_failed_lists:
                if proc_failed_list:
                    all_failed.extend(proc_failed_list)
            all_failed = list(set(all_failed))
            
            if all_failed:
                print(f'å¤±è´¥æ ·æœ¬æ•°: {len(all_failed)}')
                with open(os.path.join(save_dir, "failed_samples.txt"), 'w') as f:
                    for name in sorted(all_failed):
                        f.write(name + "\n")
                print(f'å¤±è´¥æ ·æœ¬åˆ—è¡¨å·²ä¿å­˜åˆ°: {os.path.join(save_dir, "failed_samples.txt")}')
        
        # ä¿å­˜è¯¦ç»†çš„å¤„ç†è®°å½•
        # ä¿å­˜è¯¦ç»†çš„å¤„ç†è®°å½•
        import datetime
        log_file = os.path.join(save_dir, "processing_log.txt")

        # å…ˆç»Ÿè®¡ï¼ˆé¿å…å˜é‡åå†²çªï¼‰
        processed_keys = set()
        for fname in os.listdir(save_dir):
            fp = os.path.join(save_dir, fname)
            if os.path.isfile(fp) and fname.endswith('.npy'):
                processed_keys.add(extract_number_key(fname))
            elif os.path.isfile(fp) and fname.startswith('batch_') and fname.endswith('.npz'):
                try:
                    with np.load(fp, allow_pickle=True) as z:
                        if 'sample_names' in z:
                            for s in z['sample_names']:
                                # âš ï¸ å…³é”®ä¿®å¤ï¼šsample_namesä¸­å·²ç»å­˜å‚¨çš„æ˜¯number_keyï¼Œä¸è¦å†æ¬¡æå–
                                processed_keys.add(str(s))
                except Exception:
                    pass

        total_processed = len(processed_keys)
        # ä½¿ç”¨æºç›®å½•çš„å®é™…å›¾ç‰‡æ€»æ•°ï¼ˆä¸1Dç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
        progress_pct = (total_processed / total_source_images * 100) if total_source_images > 0 else 0.0

        with open(log_file, 'a', encoding='utf-8') as fh:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            fh.write(f"\n{'='*80}\n")
            fh.write(f"å¤„ç†å®Œæˆæ—¶é—´: {timestamp}\n")
            fh.write(f"{'='*80}\n")
            fh.write(f"æœ¬æ¬¡å¤„ç†:\n")
            fh.write(f"  - æˆåŠŸå¤„ç†: {total_saved} å¼ å›¾ç‰‡\n")
            fh.write(f"  - å„GPUå¤„ç†æ•°é‡: {all_idx.cpu().tolist()}\n")
            if all_failed:
                fh.write(f"  - å¤±è´¥æ ·æœ¬æ•°: {len(all_failed)}\n")
            fh.write(f"\næ€»ä½“è¿›åº¦:\n")
            fh.write(f"  - æºç›®å½•å›¾ç‰‡æ€»æ•°: {total_source_images} å¼ \n")
            fh.write(f"  - å·²å¤„ç†æ€»æ•°: {total_processed} å¼ \n")
            fh.write(f"  - å¾…å¤„ç†æ•°é‡: {total_source_images - total_processed} å¼ \n")
            fh.write(f"  - å®Œæˆè¿›åº¦: {progress_pct:.2f}%\n")
            fh.write(f"\né…ç½®ä¿¡æ¯:\n")
            fh.write(f"  - GPUæ•°é‡: {accelerator.num_processes}\n")
            fh.write(f"  - æ‰¹æ¬¡å¤§å°: {bz}\n")
            fh.write(f"  - VAEç±»å‹: 2D (Autoencoder)\n")
            fh.write(f"  - è¾“å…¥å›¾åƒç›®å½•ï¼ˆembeddings/masksï¼‰: {input_image_path}\n")
            fh.write(f"  - è¾“å‡ºå›¾åƒç›®å½•ï¼ˆmomentsï¼‰: {output_image_path}\n")
            fh.write(f"  - ä¿å­˜ç›®å½•: {save_dir}\n")
            fh.write(f"{'='*80}\n")

        
        print(f'\nå¤„ç†è®°å½•å·²ä¿å­˜åˆ°: {log_file}')
        print(f'æ‰€æœ‰ç‰¹å¾å·²ä¿å­˜åˆ°: {save_dir}')
        print(f'\næ€»ä½“è¿›åº¦ç»Ÿè®¡:')
        print(f'  æºç›®å½•æ€»å›¾ç‰‡æ•°: {total_source_images}')
        print(f'  å·²å¤„ç†æ€»æ•°: {total_processed}')
        print(f'  å¾…å¤„ç†æ•°é‡: {total_source_images - total_processed}')
        print(f'  å®Œæˆè¿›åº¦: {progress_pct:.2f}%')
        print(f'==================\n')
        
        # æ ‡è®°æœ¬æ¬¡è¿è¡ŒæˆåŠŸå®Œæˆ
        success_file = os.path.join(save_dir, f".run_{run_id}_completed")
        with open(success_file, 'w') as f:
            f.write(f"Completed at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        print(f"æœ¬æ¬¡è¿è¡Œå·²æ ‡è®°ä¸ºæˆåŠŸå®Œæˆ: {os.path.basename(success_file)}")

if __name__ == '__main__':
    # ====================================================================================
    # åŒè·¯å¾„ç‰¹å¾æå–è¯´æ˜ï¼š
    # 
    # æœ¬è„šæœ¬æ”¯æŒä»ä¸¤ä¸ªä¸åŒçš„å›¾åƒè·¯å¾„æå–ä¸åŒçš„ç‰¹å¾ï¼š
    # - INPUT_IMAGE_PATH: è¾“å…¥å›¾åƒè·¯å¾„ï¼ˆç”¨äºæå–embeddingså’Œmasksï¼‰
    # - OUTPUT_IMAGE_PATH: è¾“å‡ºå›¾åƒè·¯å¾„ï¼ˆç”¨äºæå–momentsï¼‰
    # 
    # å¢é‡å¤„ç†è¯´æ˜ï¼š
    # - æ¯æ¬¡è¿è¡Œä¼šè‡ªåŠ¨æ‰«ææºç›®å½•çš„æ‰€æœ‰å›¾ç‰‡ï¼ˆåŒ…æ‹¬æ–°å¢çš„ï¼‰
    # - è‡ªåŠ¨æ£€æµ‹å¹¶è·³è¿‡å·²å¤„ç†çš„å›¾ç‰‡ï¼ˆåŸºäºä¿å­˜ç›®å½•ä¸­çš„ .npy æ–‡ä»¶ï¼‰
    # - åªå¤„ç†æœªå¤„ç†çš„å›¾ç‰‡
    # - æ”¯æŒä¸­æ–­åç»§ç»­å¤„ç†
    # - é€‚åˆæ•°æ®ä¸æ–­å¢åŠ çš„åœºæ™¯
    # 
    # æ€§èƒ½ä¼˜åŒ–ï¼ˆé’ˆå¯¹8å¡H100 80GBï¼‰ï¼š
    # - å·²å®ç°Janusæ‰¹é‡å¤„ç†ï¼ˆ5-10xåŠ é€Ÿï¼‰
    # - é»˜è®¤batch size=1024ï¼ˆå……åˆ†åˆ©ç”¨80GBæ˜¾å­˜ï¼‰
    # - ä¼˜åŒ–çš„DataLoaderé…ç½®ï¼ˆnum_workers=16, prefetch_factor=8ï¼‰
    # 
    # ä½¿ç”¨æ–¹å¼ï¼š
    #   bash run_multi_gpu_2D.sh
    # 
    # å‚æ•°é…ç½®ï¼š
    #   åœ¨run_multi_gpu_2D.shä¸­ä¿®æ”¹ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š
    #   - BATCH_SIZE: æ‰¹æ¬¡å¤§å°ï¼ˆä¾‹å¦‚ï¼š2048ç”¨äºH100ï¼Œ512ç”¨äºè¾ƒå°GPUï¼‰
    #   - INPUT_IMAGE_PATH: è¾“å…¥å›¾åƒè·¯å¾„
    #   - OUTPUT_IMAGE_PATH: è¾“å‡ºå›¾åƒè·¯å¾„
    #   - SAVE_DIR: ä¿å­˜ç›®å½•
    # ====================================================================================
    
    main()  # æ‰€æœ‰å‚æ•°ä»ç¯å¢ƒå˜é‡è¯»å–

